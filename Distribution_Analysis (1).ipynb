{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bb478-b683-4c85-bd7a-9cdd49b8d314",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## IMPORT LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import skew, kurtosis\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "## DEFINE FUNCTIONS\n",
    "\n",
    "def fetch_historical_data(assets, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical stock price data from Yahoo Finance.\n",
    "\n",
    "    Parameters:\n",
    "    - assets (list): List of stock tickers.\n",
    "    - start_date (str): Start date for data retrieval in \"YYYY-MM-DD\" format.\n",
    "    - end_date (str): End date for data retrieval in \"YYYY-MM-DD\" format.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Historical stock price data.\n",
    "    \"\"\"\n",
    "    if len(assets) == 1:\n",
    "        # Wrap the Series in a DataFrame for consistency:\n",
    "        data = pd.DataFrame(yf.download(assets, start=start_date, end=end_date)['Adj Close'])\n",
    "    else:\n",
    "        data = yf.download(assets, start=start_date, end=end_date)['Adj Close']\n",
    "    return data\n",
    "\n",
    "\n",
    "def calculate_returns(data, use_log_returns=False):\n",
    "    \"\"\"\n",
    "    Calculate percentage- or log returns from historical stock price data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Historical stock price data.\n",
    "    - use_log_returns (bool): If True, calculate log returns; otherwise, calculate percentage returns.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Returns data.\n",
    "    \"\"\"\n",
    "    if use_log_returns:\n",
    "        # Create an empty DataFrame to store the log returns:\n",
    "        log_returns = pd.DataFrame()\n",
    "        # Iterate over each column (asset) in the `data` DataFrame:\n",
    "        for column in data.columns:\n",
    "            # Shift the values in that column down by one position:\n",
    "            log_ret = np.log(data[column] / data[column].shift(1))\n",
    "            # Assign log returns to the corresponding column in `log_returns`.\n",
    "            log_returns[column] = log_ret\n",
    "        return log_returns\n",
    "    else:\n",
    "        # Calculate regular percentage returns\n",
    "        returns = data.pct_change().dropna()\n",
    "        return returns\n",
    "\n",
    "    \n",
    "def perform_normality_tests(data):\n",
    "    \"\"\"\n",
    "    Perform normality tests on stock returns data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Returns data.\n",
    "\n",
    "    Returns:\n",
    "    - list: Results of normality tests for each asset.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for asset in data.columns:\n",
    "\n",
    "        # Shapiro-Wilk Test\n",
    "        stat_sw, p_value_sw = shapiro(data[asset].dropna())\n",
    "        \n",
    "        # Anderson-Darling Test\n",
    "        result_ad = stats.anderson(data[asset].dropna(), dist='norm')\n",
    "        stat_ad = result_ad.statistic\n",
    "        critical_values_ad = result_ad.critical_values\n",
    "        p_value_ad = result_ad.significance_level\n",
    "\n",
    "        # Kolmogorov-Smirnov Test\n",
    "        stat_ks, p_value_ks = stats.kstest(data[asset].dropna(), 'norm')\n",
    "\n",
    "        results[asset] = {\n",
    "            'Shapiro-Wilk Test': {'Statistic': stat_sw, 'p-value': p_value_sw},\n",
    "            'Anderson-Darling Test': {'Statistic': stat_ad, 'Critical Values': critical_values_ad, 'p-value': p_value_ad},\n",
    "            'Kolmogorov-Smirnov Test': {'Statistic': stat_ks, 'p-value': p_value_ks}\n",
    "        }\n",
    "        \n",
    "    print(\"\\nNormality Test Results:\")\n",
    "    for asset, result in results.items():\n",
    "        print(f\"\\n{asset}:\")\n",
    "        print(f\"- Shapiro-Wilk Test: Statistic={result['Shapiro-Wilk Test']['Statistic']:.3f}, p-value={result['Shapiro-Wilk Test']['p-value']:.3f}\")\n",
    "        print(f\"- Anderson-Darling Test: Statistic={result['Anderson-Darling Test']['Statistic']:.3f}, Critical Values={result['Anderson-Darling Test']['Critical Values']}, p-value={result['Anderson-Darling Test']['p-value']}\")\n",
    "        print(f\"- Kolmogorov-Smirnov Test: Statistic={result['Kolmogorov-Smirnov Test']['Statistic']:.3f}, p-value={result['Kolmogorov-Smirnov Test']['p-value']:.3f}\")\n",
    "    \n",
    "    return[results]\n",
    "    \n",
    "    \n",
    "def plot_histograms_and_kde(data, use_log_returns=False):\n",
    "    \"\"\"\n",
    "    Plot histograms and kernel density plots for stock returns data.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): Returns data.\n",
    "    - use_log_returns (bool): If True, use log returns for plotting.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Display histograms and Kernel Density plots in a grid of subplots:\n",
    "    n_assets = len(data.columns) if isinstance(data, pd.DataFrame) else 1\n",
    "    n_rows = n_assets // 2 + n_assets % 2\n",
    "\n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=(15, 2.5 * n_rows))\n",
    "    returns_type = \"Log Returns\" if use_log_returns else \"Returns\"\n",
    "    fig.suptitle(f\"Distribution and Kernel Density of {returns_type} for Assets\", fontsize=16)\n",
    "\n",
    "    # List to store the axes for each asset\n",
    "    asset_axes = []\n",
    "\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for i, asset in enumerate(data.columns):\n",
    "            row, col = i // 2, i % 2\n",
    "            ax = axes[row, col]\n",
    "            asset_axes.append(ax)\n",
    "\n",
    "            # Plot Histogram:\n",
    "            ax.hist(data[asset].dropna(), bins=50, alpha=0.6, label=f'{asset} {returns_type}')\n",
    "\n",
    "            # Plot Kernel Density:\n",
    "            sns.kdeplot(data[asset].dropna(), ax=ax, label=f'{asset} KDE', color='red')\n",
    "\n",
    "            # Calculate Mean and Mode using histogram bins:\n",
    "            mean = np.mean(data[asset].dropna())\n",
    "            hist, bin_edges = np.histogram(data[asset].dropna(), bins=50)  # Adjust bins as needed\n",
    "            bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "            mode_bin = bin_centers[np.argmax(hist)]  # Bin with the highest count is considered the mode\n",
    "            median = np.median(data.dropna())\n",
    "            \n",
    "            # Plot vertical lines for mean, median, and mode for each asset\n",
    "            ax.axvline(mean, color='blue', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.4f}')\n",
    "            ax.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.4f}')\n",
    "            ax.axvline(mode_bin, color='orange', linestyle='dashed', linewidth=2, label=f'Mode: {mode_bin:.4f}')\n",
    "            ax.legend()\n",
    "\n",
    "\n",
    "    else:  # For a single series\n",
    "        ax = axes[0, 0]\n",
    "        asset_axes.append(ax)\n",
    "\n",
    "        # Plot Histogram:\n",
    "        ax.hist(data.dropna(), bins=50, alpha=0.6, label=f'{returns_type}')\n",
    "\n",
    "        # Plot Kernel Density:\n",
    "        sns.kdeplot(data.dropna(), ax=ax, label=f'Density', color='red')\n",
    "\n",
    "        # Calculate Mean and Median and Mode using histogram bins:\n",
    "        mean = np.mean(data.dropna())\n",
    "        hist, bin_edges = np.histogram(data.dropna(), bins=50)  # Adjust bins as needed\n",
    "        bin_centers = 0.5 * (bin_edges[:-1] + bin_edges[1:])\n",
    "        mode_bin = bin_centers[np.argmax(hist)]  # Bin with the highest count is considered the mode\n",
    "        median = np.median(data.dropna())\n",
    "        \n",
    "        # Plot vertical lines for mean, median, and mode for the single series\n",
    "        ax.set_title(f\"{returns_type} Distribution\")\n",
    "        ax.axvline(mean, color='blue', linestyle='dashed', linewidth=2, label=f'Mean: {mean:.4f}')\n",
    "        ax.axvline(median, color='green', linestyle='dashed', linewidth=2, label=f'Median: {median:.4f}')\n",
    "        ax.axvline(mode_bin, color='orange', linestyle='dashed', linewidth=2, label=f'Mode: {mode_bin:.4f}')\n",
    "        ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_qq_plot(data, asset, distribution_name=\"norm\", use_log_returns=False):\n",
    "    \"\"\"\n",
    "    Plot a Q-Q plot for the given data against a theoretical distribution.\n",
    "\n",
    "    :param data: Observed data\n",
    "    :type data: pandas.Series or numpy.ndarray\n",
    "    :param asset: Asset name\n",
    "    :type asset: str\n",
    "    :param distribution_name: Theoretical distribution name, default is \"Normal\"\n",
    "    :type distribution_name: str\n",
    "    :param use_log_returns: Whether to use log returns, default is False\n",
    "    :type use_log_returns: bool\n",
    "    \"\"\"\n",
    "    dist = getattr(stats, distribution_name)\n",
    "    distargs = ()\n",
    "\n",
    "    # Create subplots for Q-Q plots:\n",
    "    n_assets = len(data.columns) if isinstance(data, pd.DataFrame) else 1\n",
    "    n_rows = n_assets // 2 + n_assets % 2\n",
    "    fig, axes = plt.subplots(n_rows, 2, figsize=(15, 2.5 * n_rows))\n",
    "    returns_type = \"Log Returns\" if use_log_returns else \"Returns\"\n",
    "    fig.suptitle(f\"Quartile-Quartile Plots against {distribution_name} distribution\", fontsize=16)\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        for i, asset in enumerate(data.columns):\n",
    "            row, col = i // 2, i % 2\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            sm.qqplot(data[asset].dropna(), line='s', dist=dist, ax=ax,label=f'{asset}')\n",
    "        \n",
    "            # Skewness and Kurtosis\n",
    "            skewness = stats.skew(data[asset].dropna())\n",
    "            kurtosis = stats.kurtosis(data[asset].dropna())\n",
    "            \n",
    "            ax.set_title(f\"{asset} {returns_type} Skewness: {skewness:.4f} Kurtosis: {kurtosis:.4f}\")\n",
    "            ax.legend()\n",
    "        \n",
    "    else:  # For a single series\n",
    "        ax = axes[0, 0]\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "## CONFIGURE  \n",
    "    \n",
    "def configure():\n",
    "    # Centralise user-configurable settings here: \n",
    "    assets = [\"AAPL\",\"MSFT\", \"AMZN\", \"NVDA\", \"GOOGL\", \"TSLA\", \"UNH\", \"LLY\", \"XOM\", \"JPM\", \"V\", \"JNJ\"]\n",
    "    start_date = \"2022-01-01\"\n",
    "    end_date = \"2023-01-01\"\n",
    "    use_log_returns = False\n",
    "    distribution_name = \"norm\"\n",
    "    return assets, start_date, end_date, use_log_returns, distribution_name\n",
    "\n",
    "\n",
    "## RUN MAIN\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Get configuration settings\n",
    "    assets, start_date, end_date, use_log_returns, distribution_name = configure()    \n",
    "    \n",
    "    for asset in assets:\n",
    "    \n",
    "        # Fetch historical data for the current year:\n",
    "        data = fetch_historical_data(assets, start_date, end_date)\n",
    "        \n",
    "        # Calculate Returns:\n",
    "        returns = calculate_returns(data, use_log_returns)\n",
    "         \n",
    "    # Perform Normality Tests:\n",
    "    normality_test_results = perform_normality_tests(returns)\n",
    "    \n",
    "    # Plot Histograms and Kernel Density:\n",
    "    plot_histograms_and_kde(returns, use_log_returns)\n",
    "    \n",
    "    # Plot Quantile-Quantile Plot:\n",
    "    plot_qq_plot(returns, asset, distribution_name, use_log_returns)\n",
    "    \n",
    "\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dde0820-d1f5-48a6-9aa9-7c89251e265d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
